# Jupyter notebook for data collection
import requests
from bs4 import BeautifulSoup
import pandas as pd

def fetch_news_articles(stock_name):
    url = f"https://news.google.com/search?q={stock_name}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    articles = []
    for item in soup.find_all('h3'):
        title = item.text
        link = item.find('a')['href']
        articles.append({'title': title, 'link': link})
    
    return pd.DataFrame(articles)

stock_name = "Apple"
articles = fetch_news_articles(stock_name)
articles.to_csv("../data/raw/Apple_articles.csv", index=False)